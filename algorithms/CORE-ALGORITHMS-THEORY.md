# Core Algorithms Theory (Google Coding Interview)

> Это учебный материал, а не план подготовки.  
> Цель файла: дать понимание алгоритмов на уровне "объяснить, почему работает".

---

## 1. Алгоритмическое мышление

### 1.1 Что такое хороший алгоритм

Алгоритм в интервью оценивают по четырём осям:

1. Correctness: решение всегда даёт правильный ответ.
2. Complexity: насколько быстро и сколько памяти использует.
3. Robustness: как ведёт себя на edge cases.
4. Explainability: можешь ли ты защитить решение словами.

Если есть быстрое решение, но ты не можешь объяснить его корректность, это слабый сигнал.

### 1.2 Brute force -> структура -> оптимизация

Почти каждая сильная interview-стратегия выглядит так:

1. Формулируешь brute force (обычно O(n^2) или хуже).
2. Находишь потерю работы (повторные вычисления, лишние проходы, ненужный перебор).
3. Добавляешь структуру (HashMap/Heap/Deque/DP table/Graph traversal).
4. Получаешь O(n), O(n log n) или O(V+E).

---

## 2. Сложность: что нужно понимать глубоко

### 2.1 Почему Big-O важен

Big-O измеряет рост при больших n. На интервью важно не абсолютное время, а класс роста.

- O(n) почти всегда лучше O(n log n) на очень больших данных.
- O(n log n) почти всегда лучше O(n^2).

### 2.2 Time vs Space trade-off

Частая оптимизация: память за время.

- Two Sum: O(n^2) без памяти -> O(n) с HashMap O(n) space.
- Prefix sums: быстрые range-запросы ценой дополнительного массива.

### 2.3 Amortized analysis

Операция может быть дорогой редко, но дешёвой в среднем.

- Append в dynamic array: иногда resize O(n), но амортизированно O(1).
- Union-Find с path compression + union by rank: почти O(1) амортизированно.

---

## 3. Инварианты и корректность

Инвариант - это утверждение, которое истинно до и после каждого шага алгоритма.

Примеры:

1. Binary Search: ответ всегда внутри [left, right].
2. Sliding Window: текущее окно поддерживает нужные счётчики/ограничения.
3. BFS: первый раз, когда вершина извлечена из очереди, найдена кратчайшая дистанция в невзвешенном графе.
4. Dijkstra: когда вершина "зафиксирована", её distance уже оптимален.

Без инварианта решение выглядит как набор эвристик.

---

## 4. Основные структуры данных (смысл, не API)

### 4.1 Array / Dynamic Array

Суть: быстрый доступ по индексу, дорогие вставки в середину.

- Random access: O(1)
- Insert/delete в середине: O(n)

Ментальная модель: если нужна позиционная адресация и сканирование - array.

### 4.2 HashMap / HashSet

Суть: быстрый lookup по ключу.

- Average operations: O(1)
- Worst case: O(n) при тяжёлых коллизиях

Когда это лучше дерева: когда порядок не нужен, нужен membership/count/frequency.

### 4.3 Heap (Priority Queue)

Суть: не хранит полный порядок, хранит быстрый доступ к минимуму/максимуму.

- peek: O(1)
- push/pop: O(log n)

Используется, когда нужны top-k, онлайн-минимум/максимум, best-first выбор.

### 4.4 Deque / Monotonic structures

Суть: поддержка кандидатов для окна.

Monotonic deque позволяет поддерживать максимум/минимум окна за O(n) вместо O(nk).

### 4.5 Union-Find

Суть: быстро объединять компоненты и проверять, в одной ли они группе.

Ключевая идея эффективности:

- path compression сокращает будущие пути;
- union by rank/size ограничивает рост высоты.

---

## 5. Searching: Binary Search глубоко

### 5.1 Когда Binary Search применим

Не только "массив отсортирован".

Подходит всегда, когда есть монотонный predicate:

- для x < threshold: false
- для x >= threshold: true

Тогда ищем границу перехода.

### 5.2 Почему O(log n)

Каждый шаг делит пространство поиска примерно пополам.  
После k шагов размер ~ n / 2^k.  
Когда доходим до 1: k ~ log2(n).

### 5.3 Частые ошибки

1. Неправильная граница цикла (`<` vs `<=`).
2. Плохое обновление границ (можно зациклиться).
3. Неопределённый инвариант (непонятно, где ответ).

### 5.4 Lower bound как универсальный шаблон

Многие задачи - это "найти первый индекс, где условие выполняется".  
Если научиться мыслить lower bound, половина binary-search задач становится однотипной.

---

## 6. Graph thinking

### 6.1 Как моделировать задачу как граф

Граф появляется, когда есть:

1. состояния (вершины),
2. допустимые переходы (рёбра),
3. цель - достижимость, расстояние, порядок зависимостей.

### 6.2 BFS

BFS проходит граф слоями.

Почему даёт кратчайший путь в невзвешенном графе:

- вершины слоя d достигаются за d рёбер;
- раньше слоя d нельзя добраться до вершины слоя d;
- первый визит минимален по числу рёбер.

### 6.3 DFS

DFS строит traversal tree/forest и полезен для:

- cycle detection,
- components,
- topological ordering (через postorder).

Ключевая идея: стек вызовов хранит текущий путь.

### 6.4 Topological Sort

Работает только на DAG.

Смысл: упорядочить задачи так, чтобы все зависимости были раньше зависимых.

- Kahn (BFS по in-degree 0)
- DFS postorder

Признак цикла в Kahn: не удалось вытащить все вершины.

### 6.5 Dijkstra

Где применим:

- веса неотрицательные.

Почему корректен:

- если вершина с минимальным текущим расстоянием выбрана из priority queue,
- никакой альтернативный путь через незафиксированные вершины не может сделать её короче.

Если есть отрицательные рёбра, это свойство ломается.

### 6.6 Bellman-Ford и когда он нужен

Используй, если возможны отрицательные веса или нужна проверка отрицательного цикла.

Trade-off:

- медленнее Dijkstra (O(VE)),
- но более универсален.

---

## 7. Trees and recursion

### 7.1 Почему дерево = рекурсия

Каждый узел задаёт одинаковую подзадачу для левого и правого поддерева.  
Поэтому дерево почти всегда естественно выражается рекурсией.

### 7.2 Traversal-смысл

- Preorder: сначала узел -> удобно для сериализации/копирования структуры.
- Inorder: для BST даёт отсортированный порядок.
- Postorder: сначала дети -> удобно для задач "агрегировать снизу вверх".
- Level-order (BFS): когда важны уровни/минимальная глубина.

### 7.3 BST: главное свойство

Для каждого узла:

- все значения слева меньше,
- все справа больше.

Важно: проверка BST требует global bounds, не только сравнения с parent.

### 7.4 LCA

В обычном binary tree:

- если p и q в разных поддеревьях текущего узла -> это LCA.

В BST:

- используешь порядок значений, чтобы спускаться в нужную сторону.

---

## 8. Two Pointers и Sliding Window

### 8.1 Two Pointers

Идея: заменить двойной цикл контролируемым движением двух индексов.

Когда работает:

1. Отсортированный массив и условие монотонно реагирует на движение left/right.
2. Нужно в одном проходе удалить/сжать/переставить элементы.

### 8.2 Sliding Window

Идея: поддерживать contiguous подмассив с динамическими границами.

Ключевой разбор:

- Expand: добавили правую границу.
- Violation: условие нарушено.
- Shrink: двигаем левую, пока снова невалидность не устранена.

Почему O(n):

каждый индекс заходит в окно и выходит из окна не более одного раза.

### 8.3 Когда window не подходит

Если задача про непоследовательные элементы (subsequence без contiguous), чаще нужен DP/другой подход.

---

## 9. Dynamic Programming (DP)

### 9.1 DP - это не "формулы", а управление состоянием

DP нужен, когда:

1. Есть повторяющиеся подзадачи.
2. Оптимальный ответ складывается из оптимальных ответов меньших состояний.

### 9.2 Состояние - ядро решения

Почти все провалы в DP из-за плохого state definition.

Хороший state отвечает: "что минимально нужно помнить, чтобы принять следующий выбор".

### 9.3 Переход

Transition определяет, как из меньших состояний строить текущее.

Проверка качества transition:

- Полнота: все варианты учтены.
- Неперекрытие логики: не считаешь вариант дважды.

### 9.4 Top-down vs Bottom-up

- Top-down проще придумать.
- Bottom-up проще оптимизировать по памяти и избегать stack overhead.

### 9.5 Классические паттерны

1. 1D DP: stair/robber-like.
2. 2D grid DP: пути/стоимость в матрице.
3. Knapsack family.
4. String DP (LCS/edit distance/word break).
5. Interval DP.

### 9.6 Типовые ошибки

1. Неправильный base case.
2. Неправильный порядок обхода таблицы.
3. Слишком крупное состояние (лишняя размерность).

---

## 10. Greedy: когда можно доверять локальному выбору

Greedy корректен не потому, что "выглядит логично", а потому что есть аргумент корректности.

Типы аргументов:

1. Exchange argument: можно заменить часть оптимального решения на greedy-выбор без ухудшения.
2. Cut property: локально лучший выбор через "разрез" безопасен.

Примеры, где greedy хорошо работает:

- interval scheduling,
- Huffman,
- некоторые jump/coverage задачи,
- минимальное число ресурсов после сортировки событий.

Где greedy ломается:

- 0/1 knapsack (нужен DP),
- задачи, где локальный выбор может закрыть будущую более выгодную комбинацию.

---

## 11. Backtracking

Backtracking = DFS по пространству решений + откат состояния.

Ключевые идеи:

1. Build partial solution.
2. Проверить ограничения как можно раньше (pruning).
3. Если ветка невозможна - не углубляться.
4. После рекурсии обязательно восстановить состояние.

Сложность чаще экспоненциальная, но хороший pruning радикально снижает фактическое время.

---

## 12. String algorithms (что действительно нужно понимать)

### 12.1 KMP

Главная идея:

при mismatch не начинать сравнение с нуля, а использовать знание о совпавшем префиксе/суффиксе.

Что важно понимать:

- префикс-функция хранит длину наибольшего префикса, который также суффикс;
- за счёт этого каждый символ обрабатывается ограниченное число раз.

### 12.2 Rabin-Karp

Главная идея:

сравнивать hash подстрок, а не сами подстроки каждый раз.

Важно:

- возможны коллизии;
- при совпадении hash обычно нужна дополнительная проверка строк.

---

## 13. Bit Manipulation и Math

### 13.1 Биты

Что обязательно:

1. `x & (x - 1)` удаляет младший установленный бит.
2. `x & -x` выделяет младший установленный бит.
3. XOR-пары: `a ^ a = 0`, `a ^ 0 = a`.

Это даёт быстрые решения для single-number, power-of-two, count bits.

### 13.2 Математические основы

1. Euclidean algorithm для GCD.
2. Fast exponentiation O(log n).
3. Modular arithmetic (особенно при больших числах).
4. Sieve для массовой работы с простыми.

---

## 14. Частые сравнения, которые спрашивают в follow-up

### 14.1 BFS vs DFS

- BFS: shortest path в невзвешенном графе, уровни.
- DFS: структура графа, циклы, порядок обхода, рекурсивный анализ.

### 14.2 Dijkstra vs Bellman-Ford

- Dijkstra быстрее, но без отрицательных весов.
- Bellman-Ford медленнее, но поддерживает отрицательные веса и negative cycles.

### 14.3 Greedy vs DP

- Greedy: локальный выбор, если есть доказательство.
- DP: полный учёт состояний, когда greedy небезопасен.

### 14.4 Heap vs Sorted Array

- Heap лучше для онлайн top-k и потока.
- Sorted array лучше, когда нужны частые in-order проходы без частых модификаций.

### 14.5 HashMap vs TreeMap/BST

- HashMap: быстрее average, но без порядка.
- TreeMap/BST: O(log n), зато поддержка порядка, lower/upper bound.

---

## 15. Edge cases: обязательный минимум перед финалом

Для любой задачи проверь:

1. Empty input.
2. Single element.
3. Duplicate values.
4. Extreme values (overflow/underflow).
5. Impossible case (нет решения).
6. Multiple valid answers.

Если это не проговорить, даже правильный алгоритм выглядит "сыровато".

---

## 16. Минимальный теоретический экзамен (без кода)

### Вопросы

1. Почему binary search требует монотонности?
2. Почему BFS даёт кратчайший путь в невзвешенном графе?
3. Почему Dijkstra не работает с отрицательными рёбрами?
4. Чем state в DP отличается от "текущего индекса"?
5. Почему greedy для interval scheduling корректен?
6. Почему sliding window обычно O(n), а не O(n^2)?
7. Что именно ускоряет path compression в union-find?
8. Почему backtracking в худшем случае экспоненциальный?
9. Почему hash-based подходы могут деградировать до O(n)?
10. Когда нужно выбирать дерево вместо хеша?

### Короткие ответы

1. Без монотонности нельзя безопасно отбрасывать половину пространства.
2. BFS идёт слоями по числу рёбер; первый визит минимален.
3. Выбранная "минимальная" вершина может позже улучшиться через отрицательное ребро.
4. State хранит минимально достаточную информацию для продолжения оптимального решения.
5. Самый ранний конец освобождает максимум места для остальных интервалов.
6. Левый и правый указатели каждый двигаются максимум n раз.
7. Сокращает глубину деревьев множеств для будущих операций find.
8. Ветвление по решениям растёт как `b^d`.
9. Из-за коллизий и плохого распределения ключей.
10. Когда нужен упорядоченный обход или запросы по диапазону.

---

## 17. Что считать "глубоким пониманием" в этом проекте

Ты на нужном уровне, если по каждой core-теме можешь без кода:

1. назвать применимость,
2. назвать инвариант,
3. объяснить корректность в 3-5 предложениях,
4. дать асимптотику и её обоснование,
5. назвать минимум один контрпример/ограничение.

Если этот уровень достигнут, переход от "учу алгоритмы" к "решаю незнакомые задачи" становится системным.
