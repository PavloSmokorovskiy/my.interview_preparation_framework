# Полный гайд по алгоритмам

**Цель:** Понимание каждого алгоритма — что это, когда использовать, какая сложность.

> **Принцип:** Фокус на концепциях, инвариантах и выборе алгоритма.
>
> Для углублённой теории по принципам, инвариантам и корректности смотри:
> `algorithms/CORE-ALGORITHMS-THEORY.md`

---

# Часть 1: СОРТИРОВКИ

## Обзор сортировок

| Алгоритм | Time (avg) | Time (worst) | Space | Stable | Когда использовать |
|----------|------------|--------------|-------|--------|-------------------|
| Bubble | O(n²) | O(n²) | O(1) | Да | Учебный, никогда в продакшене |
| Selection | O(n²) | O(n²) | O(1) | Нет | Минимум свопов нужен |
| Insertion | O(n²) | O(n²) | O(1) | Да | Почти отсортированные данные |
| **Merge** | O(n log n) | O(n log n) | O(n) | Да | Стабильность важна, linked lists |
| **Quick** | O(n log n) | O(n²) | O(log n) | Нет | Общий случай, in-place |
| **Heap** | O(n log n) | O(n log n) | O(1) | Нет | Гарантированный O(n log n), in-place |
| Counting | O(n+k) | O(n+k) | O(k) | Да | Целые числа в известном диапазоне |
| Radix | O(d·n) | O(d·n) | O(n+k) | Да | Числа с фиксированным числом цифр |

**Запомни:** Merge/Quick/Heap — три главных. O(n log n) — оптимум для сравнительных сортировок.

---

## Bubble Sort

**Что это:** Многократно проходим по массиву, меняя соседние элементы если они в неправильном порядке.

**Идея:** Большие элементы "всплывают" наверх как пузырьки.

**Сложность:**
- Time: O(n²) average и worst
- Space: O(1)

**Когда использовать:** Никогда в реальном коде. Только для обучения.

**Запомни:** "Пузырёк всплывает" — большие элементы уходят в конец.

---

## Selection Sort

**Что это:** Находим минимум в неотсортированной части, ставим в конец отсортированной.

**Идея:** На каждом шаге выбираем (select) минимальный элемент.

**Сложность:**
- Time: O(n²) всегда (даже на отсортированном)
- Space: O(1)

**Когда использовать:** Когда память критична и нужно минимум свопов.

**Запомни:** "Выбираем минимум" — ровно n-1 своп за всю сортировку.

---

## Insertion Sort

**Что это:** Берём элементы по одному и вставляем на правильное место в отсортированную часть.

**Идея:** Как сортировка карт в руке — берёшь карту, вставляешь куда надо.

**Сложность:**
- Time: O(n²) worst, **O(n) на почти отсортированных данных**
- Space: O(1)

**Когда использовать:**
- Массив почти отсортирован
- Маленькие массивы (< 10-20 элементов)
- Как часть более сложных алгоритмов (Timsort)

**Запомни:** "Вставляем карту" — отлично для почти отсортированных данных.

---

## Merge Sort ⭐

**Что это:** Разделяем массив пополам, сортируем каждую половину, сливаем обратно.

**Идея:** Divide and Conquer — разделяй и властвуй.

```
[38, 27, 43, 3]
       ↓ split
[38, 27] [43, 3]
   ↓        ↓
[27, 38] [3, 43]
       ↓ merge
[3, 27, 38, 43]
```

**Сложность:**
- Time: O(n log n) **всегда** (гарантированно)
- Space: O(n) — нужен дополнительный массив

**Когда использовать:**
- Стабильность важна
- Linked lists (не нужна доп. память для merge)
- Внешняя сортировка (файлы не влезают в память)
- Нужна гарантия O(n log n)

**Запомни:** "Разделяй-сортируй-сливай" — стабильный, гарантированный O(n log n), но O(n) памяти.

---

## Quick Sort ⭐

**Что это:** Выбираем pivot, разделяем массив на "меньше pivot" и "больше pivot", рекурсивно сортируем части.

**Идея:** Partition — всё что меньше pivot слева, больше — справа.

```
[3, 7, 8, 5, 2, 1, 9, 4]  pivot=4
         ↓ partition
[3, 2, 1] [4] [7, 8, 5, 9]
    ↓           ↓
[1, 2, 3] [4] [5, 7, 8, 9]
```

**Сложность:**
- Time: O(n log n) average, **O(n²) worst** (плохой pivot)
- Space: O(log n) — стек рекурсии

**Когда использовать:**
- Общий случай — обычно самый быстрый на практике
- In-place нужен (O(1) доп. памяти кроме стека)
- Cache-friendly (хорошая локальность)

**Как избежать O(n²):**
- Random pivot
- Median-of-three
- Introsort (switch to heapsort при глубокой рекурсии)

**Запомни:** "Pivot в центре, меньше слева" — быстрый на практике, но O(n²) в worst case.

---

## Heap Sort

**Что это:** Строим max-heap, извлекаем максимум, повторяем.

**Идея:** Heap всегда даёт максимум за O(log n).

**Сложность:**
- Time: O(n log n) **всегда**
- Space: O(1) — in-place

**Когда использовать:**
- Нужна гарантия O(n log n) без доп. памяти
- Introsort использует как fallback

**Почему не всегда:**
- Плохая cache locality
- На практике медленнее Quick Sort

**Запомни:** "Heap = гарантированный O(n log n) in-place" — но медленнее Quick на практике.

---

## Counting Sort

**Что это:** Считаем количество каждого элемента, потом восстанавливаем массив.

**Идея:** Не сравниваем элементы — просто считаем.

**Сложность:**
- Time: O(n + k), где k — диапазон значений
- Space: O(k)

**Когда использовать:**
- Целые числа
- Известный небольшой диапазон (k ≤ n)
- Пример: сортировка оценок 1-100

**Ограничения:**
- Только целые числа
- k должно быть разумным (не 10⁹)

**Запомни:** "Считаем, не сравниваем" — O(n) если диапазон небольшой.

---

## Radix Sort

**Что это:** Сортируем по цифрам: сначала по единицам, потом по десяткам, и т.д.

**Идея:** d раундов counting sort по каждой цифре.

**Сложность:**
- Time: O(d · n), где d — количество цифр
- Space: O(n + k)

**Когда использовать:**
- Числа с фиксированным количеством цифр
- Строки фиксированной длины

**Запомни:** "Цифра за цифрой" — линейный для чисел с ограниченным числом цифр.

---

# Часть 2: ПОИСК

## Linear Search

**Что это:** Проходим по всем элементам, пока не найдём нужный.

**Сложность:**
- Time: O(n)
- Space: O(1)

**Когда использовать:**
- Данные не отсортированы
- Одноразовый поиск (сортировать дороже)

---

## Binary Search ⭐

**Что это:** Поиск в отсортированном массиве путём деления пополам.

**Идея:** Сравниваем с серединой → идём влево или вправо → повторяем.

```
Ищем 7 в [1, 3, 5, 7, 9, 11, 13]
          mid=7 ✓ найден!

Ищем 6 в [1, 3, 5, 7, 9, 11, 13]
          mid=7, 6<7 → ищем слева
   [1, 3, 5]
      mid=3, 6>3 → ищем справа
         [5]
         5≠6 → не найден
```

**Сложность:**
- Time: O(log n)
- Space: O(1) итеративно, O(log n) рекурсивно

**Когда использовать:**
- Массив **отсортирован**
- Нужно найти элемент или границу
- "Найти минимальное/максимальное, удовлетворяющее условию"

**Вариации:**
- **Lower bound:** первый элемент >= target
- **Upper bound:** первый элемент > target
- **Search in rotated array:** модифицированный binary search

**Типичные задачи:**
- Поиск в отсортированном массиве
- Search insert position
- Find first/last occurrence
- Search in rotated sorted array
- Finding peak element

**Запомни:** "Отсортирован + нужен log n = Binary Search"

---

## Binary Search вариации

### Lower Bound
**Что это:** Найти первый элемент >= target (или позицию для вставки).

**Применение:**
- Найти первое вхождение
- Позиция для вставки с сохранением сортировки

### Upper Bound
**Что это:** Найти первый элемент > target.

**Применение:**
- Найти последнее вхождение (upper_bound - 1)
- Количество элементов <= x

### Binary Search on Answer
**Что это:** Когда ответ монотонен — ищем границу.

**Пример:** "Минимальная скорость, чтобы успеть за T часов"
- Маленькая скорость → не успеваем (false)
- Большая скорость → успеваем (true)
- Binary search по скорости!

---

# Часть 3: ГРАФЫ

## Представление графов

### Adjacency List (список смежности)
```
0 → [1, 2]
1 → [0, 3]
2 → [0, 3]
3 → [1, 2]
```
- Space: O(V + E)
- Проверка ребра: O(degree)
- Перебор соседей: O(degree)

**Когда:** Разреженные графы (E << V²)

### Adjacency Matrix (матрица смежности)
```
    0  1  2  3
0 [ 0, 1, 1, 0 ]
1 [ 1, 0, 0, 1 ]
2 [ 1, 0, 0, 1 ]
3 [ 0, 1, 1, 0 ]
```
- Space: O(V²)
- Проверка ребра: O(1)
- Перебор соседей: O(V)

**Когда:** Плотные графы (E ≈ V²)

---

## BFS (Breadth-First Search) ⭐

**Что это:** Обход графа "в ширину" — сначала все соседи, потом соседи соседей.

**Идея:** Используем очередь (Queue). Обрабатываем вершины по "волнам" от источника.

```
    1 — 2
   /     \
  0       4
   \     /
    3 — 5

BFS от 0: 0 → 1,3 → 2,5 → 4
Порядок: 0, 1, 3, 2, 5, 4
```

**Сложность:**
- Time: O(V + E)
- Space: O(V) — очередь

**Когда использовать:**
- **Кратчайший путь в невзвешенном графе** ⭐
- Поиск на уровне (level-order)
- Проверка связности
- Найти все вершины на расстоянии k

**Типичные задачи:**
- Shortest path in unweighted graph
- Word ladder
- Rotting oranges
- 01 Matrix (nearest 0)

**Запомни:** "BFS = Queue = кратчайший путь (невзвешенный)"

---

## DFS (Depth-First Search) ⭐

**Что это:** Обход графа "в глубину" — идём как можно дальше, потом возвращаемся.

**Идея:** Используем стек (или рекурсию). Идём до тупика, потом backtrack.

```
    1 — 2
   /     \
  0       4
   \     /
    3 — 5

DFS от 0: 0 → 1 → 2 → 4 → 5 → 3
```

**Сложность:**
- Time: O(V + E)
- Space: O(V) — стек рекурсии

**Когда использовать:**
- Обход всех вершин
- Поиск цикла
- Topological sort
- Связные компоненты
- Генерация всех путей

**Типичные задачи:**
- Number of islands
- Clone graph
- Course schedule (cycle detection)
- All paths from source to target

**Запомни:** "DFS = Stack/рекурсия = полный обход, циклы, топологическая сортировка"

---

## BFS vs DFS

| Аспект | BFS | DFS |
|--------|-----|-----|
| Структура | Queue | Stack/рекурсия |
| Порядок | По уровням | В глубину |
| Память | O(ширина) | O(глубина) |
| Кратчайший путь | ✓ (невзвешенный) | ✗ |
| Обход всего | ✓ | ✓ |
| Цикл | ✓ | ✓ (проще) |

**Правило:**
- Нужен **кратчайший путь** → BFS
- Нужно **обойти всё** или найти **цикл** → DFS
- Дерево → обычно DFS

---

## Dijkstra's Algorithm ⭐

**Что это:** Кратчайший путь от источника до всех вершин во **взвешенном графе с неотрицательными весами**.

**Идея:** Greedy + Priority Queue. Всегда берём вершину с минимальным текущим расстоянием.

```
     1
  A ——— B
  |     |
 4|     |2
  |     |
  C ——— D
     3

Dijkstra от A:
A: 0
B: 1 (через A)
D: 3 (через A→B)
C: 4 (через A)
```

**Сложность:**
- Time: O((V + E) log V) с priority queue
- Space: O(V)

**Когда использовать:**
- Кратчайший путь во **взвешенном графе**
- Все веса **неотрицательные**

**Ограничения:**
- НЕ работает с отрицательными весами

**Типичные задачи:**
- Network delay time
- Cheapest flights within K stops
- Path with minimum effort

**Запомни:** "Dijkstra = взвешенный граф + неотрицательные веса + Priority Queue"

---

## Bellman-Ford Algorithm

**Что это:** Кратчайший путь от источника до всех вершин. Работает с **отрицательными весами**.

**Идея:** Релаксация всех рёбер V-1 раз.

**Сложность:**
- Time: O(V · E)
- Space: O(V)

**Когда использовать:**
- Есть **отрицательные веса**
- Нужно **детектировать отрицательный цикл**

**Запомни:** "Bellman-Ford = отрицательные веса + детекция отрицательных циклов"

---

## Floyd-Warshall Algorithm

**Что это:** Кратчайшие пути между **всеми парами** вершин.

**Идея:** DP. Для каждой пары (i, j) проверяем, лучше ли идти через k.

**Сложность:**
- Time: O(V³)
- Space: O(V²)

**Когда использовать:**
- Нужны расстояния между **всеми парами**
- Граф небольшой (V ≤ 500)
- Может быть отрицательные веса (но без отрицательных циклов)

**Запомни:** "Floyd-Warshall = все пары + O(V³)"

---

## Topological Sort ⭐

**Что это:** Линейный порядок вершин DAG, где для каждого ребра u→v вершина u идёт перед v.

**Идея:** Порядок зависимостей. Курс A должен быть до курса B.

```
  5 → 0 ← 4
  ↓       ↓
  2 → 3 → 1

Topological order: 5, 4, 2, 3, 1, 0 (один из вариантов)
```

**Алгоритмы:**
1. **DFS + Stack:** Добавляем в стек после обработки всех соседей
2. **Kahn's (BFS):** Начинаем с вершин без входящих рёбер

**Сложность:**
- Time: O(V + E)
- Space: O(V)

**Когда использовать:**
- Порядок выполнения задач
- Разрешение зависимостей
- Компиляция (что компилировать первым)

**Важно:** Работает только для **DAG** (Directed Acyclic Graph)

**Типичные задачи:**
- Course schedule
- Build order
- Alien dictionary

**Запомни:** "Topological = порядок зависимостей + DAG + DFS/Kahn"

---

## Union-Find (Disjoint Set) ⭐

**Что это:** Структура данных для отслеживания связных компонент.

**Операции:**
- **Find(x):** К какому множеству принадлежит x?
- **Union(x, y):** Объединить множества x и y

**Оптимизации:**
- **Path compression:** При Find сжимаем путь к корню
- **Union by rank/size:** Присоединяем меньшее к большему

**Сложность с оптимизациями:**
- Time: O(α(n)) ≈ O(1) амортизированно
- Space: O(n)

**Когда использовать:**
- Динамические связные компоненты
- Kruskal's algorithm (MST)
- Cycle detection в undirected graph
- "Объединить группы" задачи

**Типичные задачи:**
- Number of connected components
- Redundant connection
- Accounts merge
- Friend circles

**Запомни:** "Union-Find = связные компоненты + объединение групп"

---

## Minimum Spanning Tree (MST)

**Что это:** Поддерево, соединяющее все вершины с минимальным суммарным весом.

### Kruskal's Algorithm
**Идея:** Сортируем рёбра по весу, добавляем если не создаёт цикл (Union-Find).

- Time: O(E log E)
- Лучше для разреженных графов

### Prim's Algorithm
**Идея:** Начинаем с одной вершины, добавляем минимальное ребро к дереву.

- Time: O(E log V) с priority queue
- Лучше для плотных графов

**Запомни:** "MST = Kruskal (сортировка рёбер) или Prim (grow from vertex)"

---

## Cycle Detection

### В undirected графе
- **DFS:** Если встретили visited вершину (не parent) → цикл
- **Union-Find:** Если find(u) == find(v) при добавлении ребра → цикл

### В directed графе
- **DFS с тремя цветами:** WHITE (не visited), GRAY (в стеке), BLACK (finished)
- Если встретили GRAY → back edge → цикл

**Запомни:** "Undirected цикл = Union-Find проще. Directed цикл = DFS с цветами."

---

# Часть 4: ДЕРЕВЬЯ

## Tree Traversals ⭐

### Inorder (Left → Root → Right)
```
    4
   / \
  2   6
 / \ / \
1  3 5  7

Inorder: 1, 2, 3, 4, 5, 6, 7
```
**Применение:** BST в отсортированном порядке

### Preorder (Root → Left → Right)
```
Preorder: 4, 2, 1, 3, 6, 5, 7
```
**Применение:** Копирование дерева, сериализация

### Postorder (Left → Right → Root)
```
Postorder: 1, 3, 2, 5, 7, 6, 4
```
**Применение:** Удаление дерева, вычисление размера

### Level Order (BFS)
```
Level order: 4, 2, 6, 1, 3, 5, 7
```
**Применение:** Level-by-level обход, кратчайший путь в дереве

**Запомни:**
- "Inorder = отсортированный BST"
- "Pre/Post = рекурсивная структура"
- "Level = BFS"

---

## Binary Search Tree (BST)

**Свойство:** Для каждого узла: все в левом поддереве < узел < все в правом.

**Операции:**
- Search: O(h)
- Insert: O(h)
- Delete: O(h)

где h — высота дерева.

**Сбалансированный BST:** h = O(log n)
**Несбалансированный:** h = O(n) (вырожденный случай)

**Типичные задачи:**
- Validate BST
- Kth smallest in BST
- Lowest common ancestor in BST
- Convert sorted array to BST

---

## Balanced Trees (концепт)

### AVL Tree
- Строгий баланс: разница высот поддеревьев ≤ 1
- Быстрый поиск, но дорогая вставка/удаление
- Все операции O(log n)

### Red-Black Tree
- Менее строгий баланс
- Быстрее вставка/удаление чем AVL
- Используется в std::map, TreeMap

**Запомни:** Для интервью обычно достаточно знать, что они существуют и дают O(log n).

---

## Trie (Prefix Tree) ⭐

**Что это:** Дерево для хранения строк, где каждый путь от корня — префикс.

```
       root
      / | \
     a  b  c
    /   |
   p    a
  / \   |
 p   e  t
 |
 l
 |
 e

Слова: apple, ape, bat
```

**Операции:**
- Insert: O(m)
- Search: O(m)
- Prefix search: O(m)

где m — длина строки.

**Когда использовать:**
- Autocomplete
- Spell checker
- Prefix matching
- Word search in matrix

**Типичные задачи:**
- Implement Trie
- Word search II
- Design search autocomplete

**Запомни:** "Trie = префиксы + строки + O(длина слова)"

---

## Heap ⭐

**Что это:** Complete binary tree со свойством heap.

**Min-Heap:** Родитель ≤ детей → минимум в корне
**Max-Heap:** Родитель ≥ детей → максимум в корне

**Операции:**
- Insert: O(log n)
- Extract min/max: O(log n)
- Peek min/max: O(1)
- Build heap: O(n)

**Реализация:** Обычно массив.
- Parent: (i-1)/2
- Left child: 2i+1
- Right child: 2i+2

**Когда использовать:**
- Priority Queue
- K-th largest/smallest
- Merge K sorted lists
- Median in stream

**Типичные задачи:**
- Kth largest element
- Top K frequent elements
- Merge K sorted lists
- Find median from data stream

**Запомни:** "Heap = Priority Queue = быстрый min/max"

---

## Segment Tree

**Что это:** Дерево для range queries и point updates.

**Операции:**
- Build: O(n)
- Query (range): O(log n)
- Update (point): O(log n)

**Когда использовать:**
- Range sum/min/max queries
- С обновлениями отдельных элементов

**Запомни:** "Segment Tree = range queries + updates"

---

## Binary Indexed Tree (Fenwick Tree)

**Что это:** Компактная структура для prefix sum queries и point updates.

**Операции:**
- Update: O(log n)
- Prefix sum: O(log n)
- Range sum: O(log n)

**Проще в реализации** чем Segment Tree, но менее гибкий.

**Запомни:** "Fenwick = prefix sums + updates + проще Segment Tree"

---

# Часть 5: DYNAMIC PROGRAMMING

## Что такое DP? ⭐

**Определение:** Метод решения задач путём разбиения на подзадачи и сохранения результатов.

**Два ключевых свойства:**
1. **Optimal substructure:** Оптимальное решение содержит оптимальные решения подзадач
2. **Overlapping subproblems:** Одни и те же подзадачи решаются многократно

**Два подхода:**
- **Top-down (Memoization):** Рекурсия + кэш
- **Bottom-up (Tabulation):** Итеративно заполняем таблицу

---

## Memoization vs Tabulation

### Memoization (Top-down)
```java
Map<Integer, Integer> memo = new HashMap<>();

int fib(int n) {
    if (memo.containsKey(n)) return memo.get(n);
    if (n <= 1) return n;
    memo.put(n, fib(n - 1) + fib(n - 2));
    return memo.get(n);
}
```
**Плюсы:** Интуитивнее, считает только нужные подзадачи
**Минусы:** Overhead рекурсии, стек

### Tabulation (Bottom-up)
```java
int[] dp = new int[n + 1];
dp[0] = 0;
dp[1] = 1;
for (int i = 2; i <= n; i++) {
    dp[i] = dp[i - 1] + dp[i - 2];
}
```
**Плюсы:** Нет рекурсии, можно оптимизировать память
**Минусы:** Нужно продумать порядок

---

## Классические DP паттерны

### 1. Fibonacci Pattern
**Форма:** dp[i] = f(dp[i-1], dp[i-2], ...)

**Примеры:**
- Fibonacci
- Climbing stairs
- House robber

### 2. Knapsack Pattern
**Задача:** Выбрать items с ограничением на capacity.

**0/1 Knapsack:** Каждый item берём или нет
- dp[i][w] = max(dp[i-1][w], dp[i-1][w-weight[i]] + value[i])

**Unbounded Knapsack:** Item можно брать много раз
- dp[w] = max(dp[w], dp[w-weight[i]] + value[i])

**Примеры:**
- Subset sum
- Partition equal subset sum
- Coin change

### 3. LCS/LIS Pattern

**LCS (Longest Common Subsequence):**
- dp[i][j] = длина LCS для s1[0..i] и s2[0..j]
- Если s1[i] == s2[j]: dp[i][j] = dp[i-1][j-1] + 1
- Иначе: dp[i][j] = max(dp[i-1][j], dp[i][j-1])

**LIS (Longest Increasing Subsequence):**
- O(n²): dp[i] = max(dp[j] + 1) для всех j < i где arr[j] < arr[i]
- O(n log n): binary search + patience sorting

### 4. Grid DP
**Задача:** Путь в матрице (обычно из (0,0) в (n-1, m-1))

- dp[i][j] = f(dp[i-1][j], dp[i][j-1])

**Примеры:**
- Unique paths
- Minimum path sum
- Dungeon game

### 5. Interval DP
**Задача:** Оптимум на интервале [i, j]

- dp[i][j] = f(dp[i][k], dp[k][j]) для всех k в (i, j)

**Примеры:**
- Matrix chain multiplication
- Burst balloons
- Palindrome partitioning

### 6. State Machine DP
**Задача:** Состояния с переходами

**Примеры:**
- Best time to buy/sell stock (hold/not hold)
- House robber

---

## Признаки DP задачи

1. "Сколько способов...?" → Скорее всего DP
2. "Минимальное/максимальное..." → Оптимизация → DP или Greedy
3. "Можно ли...?" → Да/Нет → Часто DP
4. Choices + последствия → DP

**Как подходить:**
1. Определи состояние (что нужно знать)
2. Определи переход (как связаны состояния)
3. Определи base case
4. Определи порядок вычислений
5. (Опционально) Оптимизируй память

---

# Часть 6: GREEDY

## Что такое Greedy? ⭐

**Идея:** На каждом шаге делаем локально оптимальный выбор.

**Когда работает:**
- Локальный оптимум ведёт к глобальному
- "Greedy choice property" + "Optimal substructure"

**Опасность:** Не всегда работает! Нужно доказательство (или интуиция).

---

## Классические Greedy задачи

### Activity Selection
**Задача:** Максимум непересекающихся интервалов.
**Greedy:** Сортируем по концу, берём если не пересекается.

### Fractional Knapsack
**Задача:** Knapsack, но можно брать части items.
**Greedy:** Сортируем по value/weight, берём жадно.

### Huffman Coding
**Задача:** Оптимальное кодирование символов.
**Greedy:** Объединяем два минимальных.

### Jump Game
**Задача:** Можно ли добраться до конца?
**Greedy:** Отслеживаем максимальную достижимую позицию.

---

## Greedy vs DP

| Greedy | DP |
|--------|-----|
| Один выбор на шаг | Все варианты |
| Не пересматриваем | Храним все решения |
| O(n) или O(n log n) | O(n²) или больше |
| Не всегда работает | Всегда работает (если применим) |

**Совет:** Сначала попробуй greedy. Если контрпример — DP.

---

# Часть 7: TWO POINTERS ⭐

## Что это?

**Идея:** Два указателя, движущиеся по массиву/строке.

## Паттерны

### 1. Opposite Direction (навстречу)
```java
int left = 0, right = n - 1;
while (left < right) {
    // логика
    left++; // или right--;
}
```
**Примеры:**
- Two Sum (sorted array)
- Container with most water
- Valid palindrome
- 3Sum, 4Sum

### 2. Same Direction (в одном направлении)
```java
int slow = 0, fast = 0;
while (fast < n) {
    // логика
    fast++;
    if (condition) slow++;
}
```
**Примеры:**
- Remove duplicates
- Move zeroes
- Linked list cycle (fast/slow)

### 3. Two Arrays
```java
int i = 0, j = 0;
while (i < n && j < m) {
    // сравниваем arr1[i] и arr2[j]
}
```
**Примеры:**
- Merge sorted arrays
- Intersection of arrays

---

## Когда использовать

- Отсортированный массив + "найти пару"
- Подмассив с условием
- Linked list (fast/slow)
- Merge операции

---

# Часть 8: SLIDING WINDOW ⭐

## Что это?

**Идея:** "Окно" фиксированного или переменного размера, скользящее по массиву/строке.

## Паттерны

### 1. Fixed Size Window
```java
// Сумма/свойство окна размера k
int windowSum = 0;
for (int i = 0; i < k; i++) {
    windowSum += arr[i];
}
for (int i = k; i < n; i++) {
    windowSum += arr[i] - arr[i - k];
    // обрабатываем windowSum
}
```
**Примеры:**
- Max sum subarray of size k
- Average of subarrays of size k

### 2. Variable Size Window
```java
// Минимальное/максимальное окно с условием
int left = 0;
for (int right = 0; right < n; right++) {
    // расширяем: добавляем arr[right]
    while (conditionBroken) {
        // сужаем: убираем arr[left]
        left++;
    }
    // обрабатываем окно [left, right]
}
```
**Примеры:**
- Minimum window substring
- Longest substring without repeating
- Longest substring with K distinct characters

---

## Когда использовать

- "Подмассив/подстрока" + условие
- "Contiguous" в условии
- Оптимизация brute force O(n²) → O(n)

---

# Часть 9: BACKTRACKING

## Что это? ⭐

**Идея:** Построение решения по частям с откатом при неудаче.

**Template:**
```java
void backtrack(State state, List<Result> results) {
    if (isSolution(state)) {
        saveSolution(state, results);
        return;
    }

    for (Choice choice : choices) {
        if (isValid(choice)) {
            makeChoice(choice, state);
            backtrack(state, results);
            undoChoice(choice, state);  // backtrack
        }
    }
}
```

---

## Классические задачи

### Subsets (все подмножества)
- Include/exclude каждый элемент
- 2^n результатов

### Permutations (все перестановки)
- Выбираем каждый элемент на каждую позицию
- n! результатов

### Combinations (все комбинации)
- C(n, k) результатов

### N-Queens
- Размещаем ферзей по одному
- Проверяем конфликты
- Откатываемся при конфликте

---

## Backtracking vs DFS

**Backtracking** = DFS + pruning (отсечение)

- DFS обходит всё
- Backtracking отсекает невозможные ветки рано

---

# Часть 10: СТРОКОВЫЕ АЛГОРИТМЫ

## Pattern Matching

### Naive (Brute Force)
- Time: O(n·m)
- Сравниваем pattern с каждой позиции

### KMP (Knuth-Morris-Pratt)
- Time: O(n + m)
- Используем "failure function" чтобы не начинать сначала
- **Идея:** Используем информацию о совпавшей части

### Rabin-Karp
- Time: O(n + m) average, O(n·m) worst
- Используем хэши для быстрого сравнения
- **Идея:** Сравниваем хэши, при совпадении проверяем строку

---

## String Hashing

**Идея:** Преобразуем строку в число для быстрого сравнения.

**Rolling Hash:** Пересчитываем хэш за O(1) при сдвиге окна.

**Применение:**
- Pattern matching
- Finding duplicate substrings
- Longest common substring

---

# Часть 11: МАТЕМАТИЧЕСКИЕ АЛГОРИТМЫ

## GCD и LCM

**GCD (Greatest Common Divisor):**
- Euclidean algorithm: gcd(a, b) = gcd(b, a % b)
- Time: O(log(min(a, b)))

**LCM (Least Common Multiple):**
- lcm(a, b) = a * b / gcd(a, b)

---

## Sieve of Eratosthenes

**Задача:** Найти все простые до n.

**Идея:** Вычёркиваем составные, начиная с 2.

- Time: O(n log log n)
- Space: O(n)

---

## Fast Exponentiation

**Задача:** Вычислить a^n за O(log n).

**Идея:**
- a^n = (a^(n/2))² если n чётное
- a^n = a · a^(n-1) если n нечётное

---

## Bit Manipulation

### Основные операции
- `x & (x-1)` — убрать последний установленный бит
- `x & -x` — получить последний установленный бит
- `x | (1 << k)` — установить k-й бит
- `x & ~(1 << k)` — сбросить k-й бит
- `x ^ (1 << k)` — переключить k-й бит

### XOR свойства
- a ^ a = 0
- a ^ 0 = a
- Коммутативность и ассоциативность

**Применение:**
- Single number (найти уникальный)
- Подсчёт битов
- Power of two check: n & (n-1) == 0

---

# Итого: Когда что использовать

## Quick Reference

| Условие задачи | Алгоритм/Подход |
|---------------|-----------------|
| Отсортирован + поиск | Binary Search |
| Кратчайший путь (невзвешенный) | BFS |
| Кратчайший путь (взвешенный, веса ≥ 0) | Dijkstra |
| Кратчайший путь (отрицательные веса) | Bellman-Ford |
| Все пары кратчайших путей | Floyd-Warshall |
| Порядок зависимостей | Topological Sort |
| Связные компоненты | Union-Find / DFS |
| Подзадачи + оптимум | DP |
| Локальный = глобальный оптимум | Greedy |
| Пара в отсортированном | Two Pointers |
| Подмассив/подстрока | Sliding Window |
| Все комбинации/перестановки | Backtracking |
| Min/Max быстро | Heap |
| Префиксы строк | Trie |
| Range queries + updates | Segment Tree |

---

**Удачи на собеседовании!**
